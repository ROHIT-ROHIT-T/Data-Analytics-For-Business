{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "072fe1a0",
      "metadata": {
        "id": "072fe1a0"
      },
      "source": [
        "# Lab 2: Google Colab\n",
        "\n",
        "In this lab, we will take our first steps toward running our code in the cloud. One of the simplest way to accomplish this is through Google's free (although, there is a paid Pro version) service, **Colab**.\n",
        "\n",
        "This lab has 5 main parts:\n",
        "\n",
        "- **Part 1**: Get set up with Google Colab\n",
        "- **Part 2**: Get the neural network you created in **Lab 1: Exercise 7** running without error in Google Colab\n",
        "- **Part 3**: Preprocess images for use in **Part 4**\n",
        "- **Part 4**: Modify the network of **Part 2** so that it can work with the data from **Part 3**\n",
        "- **Part 5**: Modify the network of **Part 4** to improve the accuracy\n",
        "\n",
        "## Grading\n",
        "\n",
        "Please read all instructions carefully, including the following notes:\n",
        "- include only FINAL code unless directed otherwise\n",
        "- all code should be in Keras/Python\n",
        "- all code should run error free in Google Colab\n",
        "- marks will be deducted for formatting that makes the lab difficult to understand\n",
        "- marks will be deducted for unnecessary code, that is, code that is not needed to accomplish the required task\n",
        "\n",
        "## What to submit\n",
        "\n",
        "- a copy of this completed .ipynb file (can be accomplished in Colab using `file/download/Download .ipynb`)\n",
        "- a link to this completed notebook on Google Colab (can be accomplished by clicking on **Share** and then selecting *Anyone with this link can edit*)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a38a5be",
      "metadata": {
        "id": "3a38a5be"
      },
      "source": [
        "## Part 1 (0 marks)\n",
        "\n",
        "To use **Colab**, you need to have a Google account. To get a free Google account, go the the [sign up](https://accounts.google.com/) and fill in the necessary information. If you already have a Google account, you can skip this step. (If you have a gmail address, then you already have a Google Account.)\n",
        "\n",
        "<img src=\"google_signup.png\" width=600 align=\"center\">\n",
        "\n",
        "Once you have an account, you will need to sign in. To do this, go to [google.com](https://google.com):\n",
        "\n",
        "<img src=\"google_signin.png\" width=600 align=\"center\">\n",
        "\n",
        "After you are signed in, navigate to [Google Colab](https://colab.research.google.com). \n",
        "\n",
        "<img src=\"colab_intro.png\" width=600 align=\"center\">\n",
        "\n",
        "From here, click on **New Notebook**, give the notebook a name and then **save** it. Now you should verify the folder structure in **Google Drive**. To do this, you should navigate back to [google.com](https://google.com), and select **Drive** from the menu at the top right:\n",
        "\n",
        "<img src=\"drive.png\" width=600 align=\"center\">\n",
        "\n",
        "Once you are in your Google Drive, you should have a folder structure identical to the following (the name you gave your notebook can be different):\n",
        "<img src=\"colab_notebook_save.png\" width=600 align=\"center\">\n",
        "\n",
        "**If you don't have this exact folder structure, your lab will not get graded!**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwpW2KJms6-W",
        "outputId": "7cc656e9-e493-471c-9938-2c310ab9b685"
      },
      "id": "nwpW2KJms6-W",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "587aed1a",
      "metadata": {
        "id": "587aed1a"
      },
      "source": [
        "## Part 2 (10 marks)\n",
        "\n",
        "Following the procedure outlined in Lab 1, reproduce the code created in Exercise 7 in Google Colab. Verify that you get similar results using the same MNIST data that you used for Lab 1.\n",
        "\n",
        "To upload the Lab 1 file (or any other file) to your Google Drive, simply click on the **New** button in the top left, and then selct **File upload**: \n",
        "\n",
        "<img src=\"lab_upload.png\" width=600 align=\"center\">\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xbx3Xgpos9xV"
      },
      "id": "xbx3Xgpos9xV",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.astype('float32') / 255\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "\n",
        "test_images = test_images.astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_890r3athFW",
        "outputId": "09bb7a6c-8f84-49d3-b218-aefb024bb03b"
      },
      "id": "R_890r3athFW",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "network_1 = Sequential()\n",
        "network_1.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "network_1.add(Dense(200, activation='relu'))\n",
        "network_1.add(Dropout(0.5))\n",
        "network_1.add(Dense(130, activation='relu'))\n",
        "network_1.add(Dense(10, activation='softmax'))\n",
        "\n",
        "network_1.summary()\n",
        "optimizer = tf.keras.optimizers.Adam(lr = 0.002)\n",
        "network_1.compile(optimizer= optimizer,\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "network_1.fit(train_images, train_labels, epochs=17, batch_size=350, verbose=1)\n",
        "\n",
        "test_loss, test_acc = network_1.evaluate(test_images, test_labels)\n",
        "print('test_acc:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5Tqu2Y6tl5R",
        "outputId": "01d0184a-cd40-4e21-f15f-eca698234880"
      },
      "id": "Q5Tqu2Y6tl5R",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 512)               401920    \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 200)               102600    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 130)               26130     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                1310      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 531,960\n",
            "Trainable params: 531,960\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/17\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 0.3311 - accuracy: 0.8996\n",
            "Epoch 2/17\n",
            "172/172 [==============================] - 10s 59ms/step - loss: 0.1224 - accuracy: 0.9640\n",
            "Epoch 3/17\n",
            "172/172 [==============================] - 8s 47ms/step - loss: 0.0897 - accuracy: 0.9726\n",
            "Epoch 4/17\n",
            "172/172 [==============================] - 7s 41ms/step - loss: 0.0659 - accuracy: 0.9794\n",
            "Epoch 5/17\n",
            "172/172 [==============================] - 7s 39ms/step - loss: 0.0534 - accuracy: 0.9832\n",
            "Epoch 6/17\n",
            "172/172 [==============================] - 4s 25ms/step - loss: 0.0452 - accuracy: 0.9857\n",
            "Epoch 7/17\n",
            "172/172 [==============================] - 4s 25ms/step - loss: 0.0368 - accuracy: 0.9884\n",
            "Epoch 8/17\n",
            "172/172 [==============================] - 4s 25ms/step - loss: 0.0312 - accuracy: 0.9901\n",
            "Epoch 9/17\n",
            "172/172 [==============================] - 4s 25ms/step - loss: 0.0316 - accuracy: 0.9897\n",
            "Epoch 10/17\n",
            "172/172 [==============================] - 4s 25ms/step - loss: 0.0244 - accuracy: 0.9922\n",
            "Epoch 11/17\n",
            "172/172 [==============================] - 4s 25ms/step - loss: 0.0273 - accuracy: 0.9915\n",
            "Epoch 12/17\n",
            "172/172 [==============================] - 7s 41ms/step - loss: 0.0235 - accuracy: 0.9927\n",
            "Epoch 13/17\n",
            "172/172 [==============================] - 7s 43ms/step - loss: 0.0224 - accuracy: 0.9923\n",
            "Epoch 14/17\n",
            "172/172 [==============================] - 7s 38ms/step - loss: 0.0213 - accuracy: 0.9934\n",
            "Epoch 15/17\n",
            "172/172 [==============================] - 6s 38ms/step - loss: 0.0158 - accuracy: 0.9948\n",
            "Epoch 16/17\n",
            "172/172 [==============================] - 4s 25ms/step - loss: 0.0198 - accuracy: 0.9937\n",
            "Epoch 17/17\n",
            "172/172 [==============================] - 4s 25ms/step - loss: 0.0158 - accuracy: 0.9952\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0937 - accuracy: 0.9812\n",
            "test_acc: 0.9811999797821045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tdSG9EDctoq9"
      },
      "id": "tdSG9EDctoq9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "abf2d197",
      "metadata": {
        "id": "abf2d197"
      },
      "source": [
        "### Extra Computational Power\n",
        "\n",
        "One reason to use Google Colab is because it offers extra computational power in the form of access to GPUs for training larger models. As this is a free service, the extra compute resources come with some limitations (see Resource Limits section in the [FAQ](https://research.google.com/colaboratory/faq.html)). To access these extra compute resources, select the **Runtime** tab: \n",
        "\n",
        "<img src=\"runtime_1.png\" width=600 align=\"center\">\n",
        "\n",
        "Then select **Change runtime type**, choose **GPU** from the drop-down menu, and click **Save**:\n",
        "\n",
        "<img src=\"runtime_2.png\" width=600 align=\"center\">\n",
        "\n",
        "Now, when you run code in that notebook, it can run on GPUs instead of CPUs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65b3841f",
      "metadata": {
        "id": "65b3841f"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc4d41cf",
      "metadata": {
        "id": "bc4d41cf"
      },
      "source": [
        "## Part 3 (25 marks)\n",
        "\n",
        "The first step here is to upload the **Lego_small** data ([source](https://www.kaggle.com/joosthazelzet/lego-brick-images) that was provided with this notebook. (**Do not use the data from the *source* link.**) To do this, just upload the entire folder to your Google Drive. When you have done that you should have a folder structure that looks something like this: \n",
        "\n",
        "<img src=\"lab_upload_lego.png\" width=600 align=\"center\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e71da679",
      "metadata": {
        "id": "e71da679"
      },
      "source": [
        "To have access to the data in your Google Drive, you will need to run the following code to 'mount' your Drive so it is accessible to the notebook you are running on Google Colab. When you run the code, following the instructions so that your notebook can access the data. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcc939c1",
      "metadata": {
        "id": "dcc939c1"
      },
      "source": [
        "Now, you need to convert the images you just uploaded into a data structure similar to the MNIST data from Lab 1. The number of images and the pixel dimensions are, however, different than the MNIST data. \n",
        "\n",
        "**The goal here is to get the data into the correct shape so that you can use it with a fully connected neural network.**\n",
        "\n",
        "To accomplish this task, you will need to:\n",
        " - load the images from the various folders of the *Leaves* data\n",
        " - make sure they are grayscale and not RGB\n",
        " - convert the images to NumPy arrays\n",
        " - resize any images that are not the correct size\n",
        " - store these arrays in the proper shape in an appropriate data structure\n",
        " - create a target array to keep track of the proper class of each image in your data\n",
        " - view a few images after processing to verify that everything is working as it should\n",
        " - convert image arrays to one-dimensional and scale the pixel values so they are between 0 and 1\n",
        " - verify the images and target arrays have the correct dimensions\n",
        " - convert string labels to integers\n",
        " \n",
        "Aside from the packages imported below, you may find the following helpful to process the images properly:\n",
        " - [info](https://realpython.com/python-pathlib/) on `Path` so you know how to create a path to the images\n",
        " - the `.name` method that can the file or directory name from a `Path` object\n",
        " - the `.reshape()` method\n",
        " - the `.append()` method\n",
        " \n",
        "**Note that not all of the tasks above have starter code below, so be sure you have completed all tasks.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "13f93a5d",
      "metadata": {
        "id": "13f93a5d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, smart_resize\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f30e32f1",
      "metadata": {
        "id": "f30e32f1"
      },
      "source": [
        "Fill in the missing elements of the starter code below. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "603dec84",
      "metadata": {
        "id": "603dec84"
      },
      "outputs": [],
      "source": [
        "p = Path().cwd()\n",
        "q = p/'drive'/'MyDrive'/'Colab_Notebooks'/'Lego_small' # use p to create a path to the data \n",
        "\n",
        "target_dict = { 'brick 1x2':0,\n",
        "               'brick 2x2':1,\n",
        "               'brick 2x4':2,\n",
        "               'plate 1x2':3,\n",
        "               'plate 2x2':4,\n",
        "                'plate 2x4':5\n",
        "}\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for fldr in q.iterdir(): \n",
        "    current_label = fldr.name  \n",
        "    for img in fldr.iterdir():\n",
        "        img =load_img(img, color_mode='grayscale') \n",
        "        img_array = img_to_array(img) \n",
        "        img_array_resized = smart_resize(img_array,[128,128])\n",
        "        img_array_reshaped = img_array_resized.reshape(128,128)\n",
        "        images.append(img_array_reshaped)\n",
        "        labels.append(current_label)\n",
        "\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use plt.imshow() to view a few of the grayscale images\n",
        "plt.imshow(images[16], cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "lNulljDauYDz",
        "outputId": "37748dfe-8f41-44dd-97b4-34566fb6db77"
      },
      "id": "lNulljDauYDz",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc8462e6ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "453e3887",
      "metadata": {
        "id": "453e3887"
      },
      "outputs": [],
      "source": [
        "labels_int = np.array([target_dict[x] for x in labels]) # use the target_dict to convert the string labels to an array of integers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3SY8XIFunCi",
        "outputId": "bab3103d-f580-44ba-e51e-8a232adf7ad7"
      },
      "id": "-3SY8XIFunCi",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4800, 128, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db81365e",
      "metadata": {
        "id": "db81365e"
      },
      "source": [
        "## Part 4 (25 marks)\n",
        "\n",
        "The next step is to modify the network of Part 2 so that it will work with the data that was processed in Part 3. \n",
        "\n",
        "Here, you will need to:\n",
        " - use `sklearn` to create training, validation, and test sets in approximately the following ratio: 70%/20%/10%\n",
        " - train your network for 10 epochs while monitoring the accuracy on the validation (to do this, you will need to modify the `.fit()` method)\n",
        " - compute the overall accuracy on the test data\n",
        " - compute the confusion matrix (use `tf.math.confusion_matrix()`)\n",
        " - from the confusion matrix, compute the accuracy for each Lego block type (see image below)\n",
        "\n",
        "<img src=\"cm-calculation.jpg\" width=600 align=\"center\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7cef6ae4",
      "metadata": {
        "id": "7cef6ae4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(images, labels_int, test_size=0.1, random_state=1)\n",
        "\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels, test_size=0.20, random_state=1)\n",
        "\n",
        "train_images = train_images.astype('float32') / 255\n",
        "train_images = train_images.reshape((3456, 128 * 128))\n",
        "\n",
        "test_images = test_images.astype('float32') / 255\n",
        "test_images = test_images.reshape((480, 128 * 128))\n",
        "\n",
        "val_images = val_images.astype('float32') / 255\n",
        "val_images = val_images.reshape((864, 128 * 128))\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "val_labels=to_categorical(val_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network_1 = Sequential()\n",
        "network_1.add(Dense(512, activation='relu', input_shape=(128 * 128,)))\n",
        "network_1.add(Dense(200, activation='relu'))\n",
        "network_1.add(Dropout(0.5))\n",
        "network_1.add(Dense(130, activation='relu'))\n",
        "network_1.add(Dense(6, activation='softmax'))"
      ],
      "metadata": {
        "id": "SgFEnPxJu47-"
      },
      "id": "SgFEnPxJu47-",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network_1.summary()\n",
        "optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
        "\n",
        "network_1.compile(optimizer='adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "                \n",
        "network_1.fit(train_images, train_labels,validation_data=(val_images, val_labels), epochs=10, batch_size=256, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AAJagP0u6Jc",
        "outputId": "ecba5825-a38d-45f9-c353-2979240a47f3"
      },
      "id": "5AAJagP0u6Jc",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_26 (Dense)            (None, 512)               8389120   \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 200)               102600    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 200)               0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 130)               26130     \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 6)                 786       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,518,636\n",
            "Trainable params: 8,518,636\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "14/14 [==============================] - 8s 481ms/step - loss: 1.3375 - accuracy: 0.4641 - val_loss: 0.7450 - val_accuracy: 0.7083\n",
            "Epoch 2/10\n",
            "14/14 [==============================] - 4s 282ms/step - loss: 0.9007 - accuracy: 0.6458 - val_loss: 0.7377 - val_accuracy: 0.7002\n",
            "Epoch 3/10\n",
            "14/14 [==============================] - 3s 217ms/step - loss: 0.7823 - accuracy: 0.7072 - val_loss: 0.6583 - val_accuracy: 0.7581\n",
            "Epoch 4/10\n",
            "14/14 [==============================] - 4s 255ms/step - loss: 0.7266 - accuracy: 0.7245 - val_loss: 0.5712 - val_accuracy: 0.7986\n",
            "Epoch 5/10\n",
            "14/14 [==============================] - 5s 346ms/step - loss: 0.6527 - accuracy: 0.7648 - val_loss: 0.5936 - val_accuracy: 0.7905\n",
            "Epoch 6/10\n",
            "14/14 [==============================] - 5s 348ms/step - loss: 0.6358 - accuracy: 0.7772 - val_loss: 0.5448 - val_accuracy: 0.7951\n",
            "Epoch 7/10\n",
            "14/14 [==============================] - 6s 457ms/step - loss: 0.5775 - accuracy: 0.7969 - val_loss: 0.4919 - val_accuracy: 0.8391\n",
            "Epoch 8/10\n",
            "14/14 [==============================] - 5s 357ms/step - loss: 0.5194 - accuracy: 0.8252 - val_loss: 0.4912 - val_accuracy: 0.8322\n",
            "Epoch 9/10\n",
            "14/14 [==============================] - 5s 354ms/step - loss: 0.4697 - accuracy: 0.8452 - val_loss: 0.4565 - val_accuracy: 0.8438\n",
            "Epoch 10/10\n",
            "14/14 [==============================] - 4s 271ms/step - loss: 0.4438 - accuracy: 0.8507 - val_loss: 0.4331 - val_accuracy: 0.8600\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc841ad6e10>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = network_1.evaluate(test_images, test_labels)\n",
        "print('test_acc:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNyY2LffvVOn",
        "outputId": "f181b023-0832-4a20-c751-ba52fc00bab3"
      },
      "id": "TNyY2LffvVOn",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 1s 41ms/step - loss: 0.4678 - accuracy: 0.8562\n",
            "test_acc: 0.856249988079071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_class=[]\n",
        "for x in range(0,len(test_images)):\n",
        "  a_class.append(np.argmax(test_labels[x]))\n",
        "\n",
        "a_class=np.array(a_class)  \n",
        "a_class.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWaUMenTvfU7",
        "outputId": "a82c914c-26bc-406e-af9e-149db20d741a"
      },
      "id": "eWaUMenTvfU7",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(480,)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=network_1.predict(test_images)\n",
        "p_class=[]      \n",
        "for x in range(0,len(test_images)):\n",
        "  p_class.append(np.argmax(prediction[x]))\n",
        "\n",
        "p_class=np.array(p_class)                           \n",
        "p_class.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kbqeGynvowX",
        "outputId": "eef3d832-3a2c-4f8c-effe-3ff96637f2a9"
      },
      "id": "-kbqeGynvowX",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(480,)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = tf.math.confusion_matrix(a_class , p_class)\n",
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRIdwqz1vypI",
        "outputId": "cabaee01-d5cf-442b-cdb3-67c303455e16"
      },
      "id": "lRIdwqz1vypI",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6, 6), dtype=int32, numpy=\n",
              "array([[70,  0,  0,  9,  4,  0],\n",
              "       [ 5, 71,  0,  0,  2,  0],\n",
              "       [ 0,  2, 67,  0,  0, 19],\n",
              "       [ 0,  0,  0, 73,  0,  0],\n",
              "       [10,  3,  0,  2, 66,  0],\n",
              "       [ 3,  2,  4,  0,  4, 64]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy for Lego block type brick 1x2')\n",
        "print(cm[0,0]/sum(cm[:,0]))\n",
        "print('Accuracy for Lego block type brick 2x2')\n",
        "print(cm[1,1]/sum(cm[:,1]))\n",
        "print('Accuracy for Lego block type brick 2x4')\n",
        "print(cm[2,2]/sum(cm[:,2]))\n",
        "print('Accuracy for Lego block type plate 1x2')\n",
        "print(cm[3,3]/sum(cm[:,3]))\n",
        "print('Accuracy for Lego block type plate 2x2')\n",
        "print(cm[4,4]/sum(cm[:,4]))\n",
        "print('Accuracy for Lego block type plate 2x4')\n",
        "print(cm[5,5]/sum(cm[:,5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk_Tqh4Kv03N",
        "outputId": "fe3ce6d6-e3a4-402c-fec6-3687a740ea0f"
      },
      "id": "Bk_Tqh4Kv03N",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Lego block type brick 1x2\n",
            "tf.Tensor(0.7954545454545454, shape=(), dtype=float64)\n",
            "Accuracy for Lego block type brick 2x2\n",
            "tf.Tensor(0.9102564102564102, shape=(), dtype=float64)\n",
            "Accuracy for Lego block type brick 2x4\n",
            "tf.Tensor(0.9436619718309859, shape=(), dtype=float64)\n",
            "Accuracy for Lego block type plate 1x2\n",
            "tf.Tensor(0.8690476190476191, shape=(), dtype=float64)\n",
            "Accuracy for Lego block type plate 2x2\n",
            "tf.Tensor(0.868421052631579, shape=(), dtype=float64)\n",
            "Accuracy for Lego block type plate 2x4\n",
            "tf.Tensor(0.7710843373493976, shape=(), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76908ba1",
      "metadata": {
        "id": "76908ba1"
      },
      "source": [
        "## Part 5 (25 marks)\n",
        "\n",
        "The final step is to modify the network of **Part 4** to improve the accuracy as much as possible. When finished:\n",
        " - train your network for as many epochs as necessary for the accuracy to stop improving\n",
        " - compute the new overall accuracy on the test data and compare with that of **Part 4**\n",
        " - compute the new confusion matrix (use `tf.math.confusion_matrix()`) and compare with that of **Part 4**\n",
        " - from the confusion matrix, compute the new accuracy for each Lego block type and compare with that of **Part 4**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "1da3a5cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1da3a5cf",
        "outputId": "bc2ba078-f918-4397-f66b-8440392d7734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "27/27 [==============================] - 5s 203ms/step - loss: 0.3164 - accuracy: 0.8970 - val_loss: 0.4199 - val_accuracy: 0.8646\n",
            "Epoch 2/500\n",
            "27/27 [==============================] - 5s 196ms/step - loss: 0.2902 - accuracy: 0.9077 - val_loss: 0.4916 - val_accuracy: 0.8553\n",
            "Epoch 3/500\n",
            "27/27 [==============================] - 6s 222ms/step - loss: 0.2745 - accuracy: 0.9071 - val_loss: 0.4090 - val_accuracy: 0.8715\n",
            "Epoch 4/500\n",
            "27/27 [==============================] - 6s 232ms/step - loss: 0.2484 - accuracy: 0.9146 - val_loss: 0.4205 - val_accuracy: 0.8738\n",
            "Epoch 5/500\n",
            "27/27 [==============================] - 5s 200ms/step - loss: 0.2222 - accuracy: 0.9265 - val_loss: 0.4464 - val_accuracy: 0.8738\n",
            "Epoch 6/500\n",
            "27/27 [==============================] - 5s 204ms/step - loss: 0.2017 - accuracy: 0.9306 - val_loss: 0.3938 - val_accuracy: 0.8877\n",
            "Epoch 7/500\n",
            "27/27 [==============================] - 5s 202ms/step - loss: 0.1646 - accuracy: 0.9433 - val_loss: 0.4311 - val_accuracy: 0.8762\n",
            "Epoch 8/500\n",
            "27/27 [==============================] - 5s 204ms/step - loss: 0.1520 - accuracy: 0.9528 - val_loss: 0.4274 - val_accuracy: 0.8796\n",
            "Epoch 9/500\n",
            "27/27 [==============================] - 7s 252ms/step - loss: 0.1316 - accuracy: 0.9537 - val_loss: 0.5036 - val_accuracy: 0.8773\n",
            "Epoch 10/500\n",
            "27/27 [==============================] - 7s 266ms/step - loss: 0.1331 - accuracy: 0.9589 - val_loss: 0.3925 - val_accuracy: 0.8854\n",
            "Epoch 11/500\n",
            "27/27 [==============================] - 6s 228ms/step - loss: 0.1160 - accuracy: 0.9592 - val_loss: 0.5241 - val_accuracy: 0.8819\n",
            "Epoch 12/500\n",
            "27/27 [==============================] - 6s 209ms/step - loss: 0.0939 - accuracy: 0.9690 - val_loss: 0.4544 - val_accuracy: 0.8831\n",
            "Epoch 13/500\n",
            "27/27 [==============================] - 7s 274ms/step - loss: 0.1163 - accuracy: 0.9633 - val_loss: 0.6511 - val_accuracy: 0.8715\n",
            "Epoch 14/500\n",
            "27/27 [==============================] - 6s 218ms/step - loss: 0.1164 - accuracy: 0.9618 - val_loss: 0.4949 - val_accuracy: 0.8947\n",
            "Epoch 15/500\n",
            "27/27 [==============================] - 6s 213ms/step - loss: 0.0932 - accuracy: 0.9693 - val_loss: 0.5115 - val_accuracy: 0.8715\n",
            "Epoch 16/500\n",
            "27/27 [==============================] - 7s 242ms/step - loss: 0.0774 - accuracy: 0.9748 - val_loss: 0.5329 - val_accuracy: 0.8877\n",
            "Epoch 17/500\n",
            "27/27 [==============================] - 6s 243ms/step - loss: 0.0648 - accuracy: 0.9812 - val_loss: 0.5343 - val_accuracy: 0.8947\n",
            "Epoch 18/500\n",
            "27/27 [==============================] - 5s 193ms/step - loss: 0.0538 - accuracy: 0.9815 - val_loss: 0.5700 - val_accuracy: 0.8657\n",
            "Epoch 19/500\n",
            "27/27 [==============================] - 6s 221ms/step - loss: 0.0583 - accuracy: 0.9777 - val_loss: 0.5264 - val_accuracy: 0.8900\n",
            "Epoch 20/500\n",
            "27/27 [==============================] - 6s 208ms/step - loss: 0.0504 - accuracy: 0.9841 - val_loss: 0.5625 - val_accuracy: 0.8900\n",
            "Epoch 21/500\n",
            "27/27 [==============================] - 6s 211ms/step - loss: 0.0500 - accuracy: 0.9855 - val_loss: 0.6397 - val_accuracy: 0.8738\n",
            "Epoch 22/500\n",
            "27/27 [==============================] - 7s 271ms/step - loss: 0.0389 - accuracy: 0.9861 - val_loss: 0.5777 - val_accuracy: 0.8935\n",
            "Epoch 23/500\n",
            "27/27 [==============================] - 6s 237ms/step - loss: 0.0463 - accuracy: 0.9858 - val_loss: 0.6835 - val_accuracy: 0.8727\n",
            "Epoch 24/500\n",
            "27/27 [==============================] - 6s 209ms/step - loss: 0.0562 - accuracy: 0.9795 - val_loss: 0.6022 - val_accuracy: 0.8831\n",
            "Epoch 25/500\n",
            "27/27 [==============================] - 6s 209ms/step - loss: 0.0473 - accuracy: 0.9829 - val_loss: 0.5546 - val_accuracy: 0.8819\n",
            "Epoch 26/500\n",
            "27/27 [==============================] - 7s 252ms/step - loss: 0.0296 - accuracy: 0.9902 - val_loss: 0.7385 - val_accuracy: 0.8727\n",
            "Epoch 27/500\n",
            "27/27 [==============================] - 6s 223ms/step - loss: 0.0527 - accuracy: 0.9812 - val_loss: 0.6164 - val_accuracy: 0.8646\n",
            "Epoch 28/500\n",
            "27/27 [==============================] - 6s 207ms/step - loss: 0.0588 - accuracy: 0.9823 - val_loss: 0.6179 - val_accuracy: 0.8808\n",
            "Epoch 29/500\n",
            "27/27 [==============================] - 6s 214ms/step - loss: 0.0746 - accuracy: 0.9751 - val_loss: 0.6726 - val_accuracy: 0.8866\n",
            "Epoch 30/500\n",
            "27/27 [==============================] - 6s 238ms/step - loss: 0.0327 - accuracy: 0.9910 - val_loss: 0.6974 - val_accuracy: 0.8669\n",
            "Epoch 31/500\n",
            "27/27 [==============================] - 5s 201ms/step - loss: 0.0392 - accuracy: 0.9867 - val_loss: 0.7876 - val_accuracy: 0.8785\n",
            "Epoch 32/500\n",
            "27/27 [==============================] - 6s 205ms/step - loss: 0.0667 - accuracy: 0.9766 - val_loss: 0.7044 - val_accuracy: 0.8947\n",
            "Epoch 33/500\n",
            "27/27 [==============================] - 6s 208ms/step - loss: 0.0699 - accuracy: 0.9771 - val_loss: 0.7300 - val_accuracy: 0.8889\n",
            "Epoch 34/500\n",
            "27/27 [==============================] - 5s 195ms/step - loss: 0.0421 - accuracy: 0.9864 - val_loss: 0.7391 - val_accuracy: 0.8750\n",
            "Epoch 35/500\n",
            "27/27 [==============================] - 5s 186ms/step - loss: 0.0361 - accuracy: 0.9858 - val_loss: 0.7543 - val_accuracy: 0.8785\n",
            "Epoch 36/500\n",
            "27/27 [==============================] - 7s 252ms/step - loss: 0.0455 - accuracy: 0.9861 - val_loss: 0.7391 - val_accuracy: 0.8889\n",
            "Epoch 37/500\n",
            "27/27 [==============================] - 6s 209ms/step - loss: 0.0396 - accuracy: 0.9873 - val_loss: 0.6239 - val_accuracy: 0.8866\n",
            "Epoch 38/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.0386 - accuracy: 0.9873 - val_loss: 0.6652 - val_accuracy: 0.8843\n",
            "Epoch 39/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0366 - accuracy: 0.9881 - val_loss: 0.6497 - val_accuracy: 0.8924\n",
            "Epoch 40/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.6962 - val_accuracy: 0.8947\n",
            "Epoch 41/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0189 - accuracy: 0.9939 - val_loss: 0.6998 - val_accuracy: 0.8993\n",
            "Epoch 42/500\n",
            "27/27 [==============================] - 5s 194ms/step - loss: 0.0174 - accuracy: 0.9936 - val_loss: 0.6458 - val_accuracy: 0.9016\n",
            "Epoch 43/500\n",
            "27/27 [==============================] - 6s 210ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.6800 - val_accuracy: 0.8947\n",
            "Epoch 44/500\n",
            "27/27 [==============================] - 5s 202ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 0.7285 - val_accuracy: 0.8935\n",
            "Epoch 45/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0077 - accuracy: 0.9980 - val_loss: 0.8422 - val_accuracy: 0.8947\n",
            "Epoch 46/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.8647 - val_accuracy: 0.8912\n",
            "Epoch 47/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 0.0245 - accuracy: 0.9928 - val_loss: 0.8191 - val_accuracy: 0.8843\n",
            "Epoch 48/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0223 - accuracy: 0.9925 - val_loss: 0.9851 - val_accuracy: 0.8785\n",
            "Epoch 49/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0621 - accuracy: 0.9832 - val_loss: 0.6795 - val_accuracy: 0.9016\n",
            "Epoch 50/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.0451 - accuracy: 0.9855 - val_loss: 0.7391 - val_accuracy: 0.8947\n",
            "Epoch 51/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0332 - accuracy: 0.9893 - val_loss: 0.6805 - val_accuracy: 0.8738\n",
            "Epoch 52/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0259 - accuracy: 0.9913 - val_loss: 0.7586 - val_accuracy: 0.8889\n",
            "Epoch 53/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.8375 - val_accuracy: 0.8843\n",
            "Epoch 54/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0107 - accuracy: 0.9971 - val_loss: 0.8978 - val_accuracy: 0.8924\n",
            "Epoch 55/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 0.8678 - val_accuracy: 0.8773\n",
            "Epoch 56/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0405 - accuracy: 0.9861 - val_loss: 0.7678 - val_accuracy: 0.8935\n",
            "Epoch 57/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0337 - accuracy: 0.9878 - val_loss: 0.7884 - val_accuracy: 0.8750\n",
            "Epoch 58/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.0348 - accuracy: 0.9893 - val_loss: 0.8440 - val_accuracy: 0.8831\n",
            "Epoch 59/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.0414 - accuracy: 0.9867 - val_loss: 0.6941 - val_accuracy: 0.8727\n",
            "Epoch 60/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0297 - accuracy: 0.9890 - val_loss: 0.7625 - val_accuracy: 0.8854\n",
            "Epoch 61/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.6951 - val_accuracy: 0.8935\n",
            "Epoch 62/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.8015 - val_accuracy: 0.8924\n",
            "Epoch 63/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.8211 - val_accuracy: 0.8981\n",
            "Epoch 64/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0151 - accuracy: 0.9942 - val_loss: 0.8323 - val_accuracy: 0.8993\n",
            "Epoch 65/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.7267 - val_accuracy: 0.9028\n",
            "Epoch 66/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.7938 - val_accuracy: 0.8912\n",
            "Epoch 67/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.8327 - val_accuracy: 0.8924\n",
            "Epoch 68/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 0.0062 - accuracy: 0.9971 - val_loss: 0.7588 - val_accuracy: 0.9039\n",
            "Epoch 69/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.0186 - accuracy: 0.9948 - val_loss: 0.8592 - val_accuracy: 0.8692\n",
            "Epoch 70/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0323 - accuracy: 0.9899 - val_loss: 0.8340 - val_accuracy: 0.8831\n",
            "Epoch 71/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0159 - accuracy: 0.9936 - val_loss: 0.7963 - val_accuracy: 0.8993\n",
            "Epoch 72/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.9083 - val_accuracy: 0.8924\n",
            "Epoch 73/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.8512 - val_accuracy: 0.8993\n",
            "Epoch 74/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.8403 - val_accuracy: 0.8981\n",
            "Epoch 75/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.8945 - val_accuracy: 0.9109\n",
            "Epoch 76/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.9128 - val_accuracy: 0.8958\n",
            "Epoch 77/500\n",
            "27/27 [==============================] - 4s 132ms/step - loss: 0.0043 - accuracy: 0.9986 - val_loss: 0.9214 - val_accuracy: 0.8970\n",
            "Epoch 78/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.9697 - val_accuracy: 0.8831\n",
            "Epoch 79/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.8515 - val_accuracy: 0.8889\n",
            "Epoch 80/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0095 - accuracy: 0.9980 - val_loss: 0.9415 - val_accuracy: 0.8796\n",
            "Epoch 81/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.9406 - val_accuracy: 0.8924\n",
            "Epoch 82/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.9013 - val_accuracy: 0.8796\n",
            "Epoch 83/500\n",
            "27/27 [==============================] - 4s 132ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 1.0204 - val_accuracy: 0.8692\n",
            "Epoch 84/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0381 - accuracy: 0.9890 - val_loss: 0.7474 - val_accuracy: 0.8831\n",
            "Epoch 85/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0507 - accuracy: 0.9832 - val_loss: 0.7743 - val_accuracy: 0.8981\n",
            "Epoch 86/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0349 - accuracy: 0.9884 - val_loss: 0.8191 - val_accuracy: 0.8866\n",
            "Epoch 87/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0266 - accuracy: 0.9905 - val_loss: 0.7757 - val_accuracy: 0.8958\n",
            "Epoch 88/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0288 - accuracy: 0.9896 - val_loss: 0.7544 - val_accuracy: 0.8843\n",
            "Epoch 89/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0614 - accuracy: 0.9815 - val_loss: 0.9608 - val_accuracy: 0.8750\n",
            "Epoch 90/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0573 - accuracy: 0.9821 - val_loss: 0.6558 - val_accuracy: 0.8877\n",
            "Epoch 91/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.7941 - val_accuracy: 0.8785\n",
            "Epoch 92/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.0132 - accuracy: 0.9965 - val_loss: 0.7515 - val_accuracy: 0.8935\n",
            "Epoch 93/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.8019 - val_accuracy: 0.8854\n",
            "Epoch 94/500\n",
            "27/27 [==============================] - 4s 132ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.7914 - val_accuracy: 0.8958\n",
            "Epoch 95/500\n",
            "27/27 [==============================] - 5s 189ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.7697 - val_accuracy: 0.9028\n",
            "Epoch 96/500\n",
            "27/27 [==============================] - 5s 205ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.8296 - val_accuracy: 0.8935\n",
            "Epoch 97/500\n",
            "27/27 [==============================] - 6s 239ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.7912 - val_accuracy: 0.9039\n",
            "Epoch 98/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 8.1918e-04 - accuracy: 1.0000 - val_loss: 0.8287 - val_accuracy: 0.9016\n",
            "Epoch 99/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 6.7901e-04 - accuracy: 1.0000 - val_loss: 0.8528 - val_accuracy: 0.8958\n",
            "Epoch 100/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 6.1928e-04 - accuracy: 0.9997 - val_loss: 0.8471 - val_accuracy: 0.8981\n",
            "Epoch 101/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.9090 - val_accuracy: 0.8947\n",
            "Epoch 102/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0146 - accuracy: 0.9962 - val_loss: 0.9112 - val_accuracy: 0.9074\n",
            "Epoch 103/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0149 - accuracy: 0.9959 - val_loss: 0.9049 - val_accuracy: 0.8877\n",
            "Epoch 104/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0102 - accuracy: 0.9971 - val_loss: 0.8899 - val_accuracy: 0.8889\n",
            "Epoch 105/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0139 - accuracy: 0.9962 - val_loss: 0.9348 - val_accuracy: 0.8877\n",
            "Epoch 106/500\n",
            "27/27 [==============================] - 4s 132ms/step - loss: 0.0476 - accuracy: 0.9870 - val_loss: 0.8879 - val_accuracy: 0.8877\n",
            "Epoch 107/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.0580 - accuracy: 0.9829 - val_loss: 0.8952 - val_accuracy: 0.8866\n",
            "Epoch 108/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.1085 - accuracy: 0.9740 - val_loss: 0.7027 - val_accuracy: 0.8889\n",
            "Epoch 109/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.0273 - accuracy: 0.9907 - val_loss: 0.6683 - val_accuracy: 0.9051\n",
            "Epoch 110/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.0109 - accuracy: 0.9959 - val_loss: 0.7866 - val_accuracy: 0.8935\n",
            "Epoch 111/500\n",
            "27/27 [==============================] - 4s 132ms/step - loss: 0.0043 - accuracy: 0.9983 - val_loss: 0.7467 - val_accuracy: 0.8924\n",
            "Epoch 112/500\n",
            "27/27 [==============================] - 4s 131ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.7843 - val_accuracy: 0.9051\n",
            "Epoch 113/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.8109 - val_accuracy: 0.9028\n",
            "Epoch 114/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0045 - accuracy: 0.9991 - val_loss: 0.8646 - val_accuracy: 0.8947\n",
            "Epoch 115/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0125 - accuracy: 0.9968 - val_loss: 0.8156 - val_accuracy: 0.8924\n",
            "Epoch 116/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.8181 - val_accuracy: 0.8889\n",
            "Epoch 117/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8392 - val_accuracy: 0.8970\n",
            "Epoch 118/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.7937 - val_accuracy: 0.9051\n",
            "Epoch 119/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 7.2113e-04 - accuracy: 1.0000 - val_loss: 0.8130 - val_accuracy: 0.8993\n",
            "Epoch 120/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 7.0815e-04 - accuracy: 1.0000 - val_loss: 0.8325 - val_accuracy: 0.9051\n",
            "Epoch 121/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 4.9266e-04 - accuracy: 1.0000 - val_loss: 0.8752 - val_accuracy: 0.9039\n",
            "Epoch 122/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 1.6572e-04 - accuracy: 1.0000 - val_loss: 0.8739 - val_accuracy: 0.9028\n",
            "Epoch 123/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 4.5804e-04 - accuracy: 1.0000 - val_loss: 0.8553 - val_accuracy: 0.9086\n",
            "Epoch 124/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 5.4588e-04 - accuracy: 0.9997 - val_loss: 0.8791 - val_accuracy: 0.9051\n",
            "Epoch 125/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 8.0254e-04 - accuracy: 0.9997 - val_loss: 0.8271 - val_accuracy: 0.9051\n",
            "Epoch 126/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 6.5857e-04 - accuracy: 0.9997 - val_loss: 0.9328 - val_accuracy: 0.9097\n",
            "Epoch 127/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 9.4501e-04 - accuracy: 0.9997 - val_loss: 1.0620 - val_accuracy: 0.8993\n",
            "Epoch 128/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.9062 - val_accuracy: 0.9062\n",
            "Epoch 129/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.8954 - val_accuracy: 0.9016\n",
            "Epoch 130/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.9131 - val_accuracy: 0.9086\n",
            "Epoch 131/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 3.9851e-04 - accuracy: 1.0000 - val_loss: 0.9053 - val_accuracy: 0.9039\n",
            "Epoch 132/500\n",
            "27/27 [==============================] - 4s 143ms/step - loss: 9.8368e-04 - accuracy: 0.9997 - val_loss: 0.8668 - val_accuracy: 0.9005\n",
            "Epoch 133/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 4.2905e-04 - accuracy: 0.9997 - val_loss: 0.9298 - val_accuracy: 0.8970\n",
            "Epoch 134/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.9778 - val_accuracy: 0.8958\n",
            "Epoch 135/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 1.0934 - val_accuracy: 0.8912\n",
            "Epoch 136/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0226 - accuracy: 0.9936 - val_loss: 1.1710 - val_accuracy: 0.8762\n",
            "Epoch 137/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0463 - accuracy: 0.9881 - val_loss: 0.9034 - val_accuracy: 0.8773\n",
            "Epoch 138/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0452 - accuracy: 0.9864 - val_loss: 0.8281 - val_accuracy: 0.8773\n",
            "Epoch 139/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0183 - accuracy: 0.9936 - val_loss: 0.7623 - val_accuracy: 0.9051\n",
            "Epoch 140/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0109 - accuracy: 0.9957 - val_loss: 0.8712 - val_accuracy: 0.8993\n",
            "Epoch 141/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.8602 - val_accuracy: 0.8924\n",
            "Epoch 142/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.9158 - val_accuracy: 0.8981\n",
            "Epoch 143/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.8606 - val_accuracy: 0.8993\n",
            "Epoch 144/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0028 - accuracy: 0.9986 - val_loss: 0.9555 - val_accuracy: 0.8947\n",
            "Epoch 145/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 1.0296 - val_accuracy: 0.8924\n",
            "Epoch 146/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0450 - accuracy: 0.9861 - val_loss: 0.9306 - val_accuracy: 0.8750\n",
            "Epoch 147/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.0516 - accuracy: 0.9844 - val_loss: 0.9905 - val_accuracy: 0.8646\n",
            "Epoch 148/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0481 - accuracy: 0.9835 - val_loss: 0.8208 - val_accuracy: 0.8727\n",
            "Epoch 149/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 0.9720 - val_accuracy: 0.8808\n",
            "Epoch 150/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0095 - accuracy: 0.9980 - val_loss: 0.7914 - val_accuracy: 0.8843\n",
            "Epoch 151/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.8128 - val_accuracy: 0.8900\n",
            "Epoch 152/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.8797 - val_accuracy: 0.8866\n",
            "Epoch 153/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.8661 - val_accuracy: 0.9028\n",
            "Epoch 154/500\n",
            "27/27 [==============================] - 4s 143ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.9095 - val_accuracy: 0.8993\n",
            "Epoch 155/500\n",
            "27/27 [==============================] - 4s 143ms/step - loss: 0.0072 - accuracy: 0.9983 - val_loss: 0.8597 - val_accuracy: 0.9028\n",
            "Epoch 156/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0041 - accuracy: 0.9980 - val_loss: 0.8775 - val_accuracy: 0.9016\n",
            "Epoch 157/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.8954 - val_accuracy: 0.9062\n",
            "Epoch 158/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.8639 - val_accuracy: 0.8970\n",
            "Epoch 159/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 1.0775 - val_accuracy: 0.8866\n",
            "Epoch 160/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0238 - accuracy: 0.9942 - val_loss: 0.9092 - val_accuracy: 0.8947\n",
            "Epoch 161/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0324 - accuracy: 0.9913 - val_loss: 1.0722 - val_accuracy: 0.8981\n",
            "Epoch 162/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0343 - accuracy: 0.9890 - val_loss: 0.8998 - val_accuracy: 0.8785\n",
            "Epoch 163/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0233 - accuracy: 0.9916 - val_loss: 1.0296 - val_accuracy: 0.8681\n",
            "Epoch 164/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0262 - accuracy: 0.9936 - val_loss: 0.8778 - val_accuracy: 0.8681\n",
            "Epoch 165/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0375 - accuracy: 0.9873 - val_loss: 0.9006 - val_accuracy: 0.8819\n",
            "Epoch 166/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0362 - accuracy: 0.9884 - val_loss: 0.6817 - val_accuracy: 0.9005\n",
            "Epoch 167/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0100 - accuracy: 0.9971 - val_loss: 0.7173 - val_accuracy: 0.8993\n",
            "Epoch 168/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.7307 - val_accuracy: 0.8993\n",
            "Epoch 169/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 6.6024e-04 - accuracy: 1.0000 - val_loss: 0.7575 - val_accuracy: 0.9028\n",
            "Epoch 170/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 9.6912e-04 - accuracy: 1.0000 - val_loss: 0.7683 - val_accuracy: 0.9039\n",
            "Epoch 171/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 5.1886e-04 - accuracy: 1.0000 - val_loss: 0.7994 - val_accuracy: 0.9109\n",
            "Epoch 172/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 4.8862e-04 - accuracy: 1.0000 - val_loss: 0.7668 - val_accuracy: 0.9074\n",
            "Epoch 173/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 3.2060e-04 - accuracy: 1.0000 - val_loss: 0.7749 - val_accuracy: 0.9028\n",
            "Epoch 174/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 2.6633e-04 - accuracy: 1.0000 - val_loss: 0.7872 - val_accuracy: 0.9039\n",
            "Epoch 175/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 2.2698e-04 - accuracy: 1.0000 - val_loss: 0.8072 - val_accuracy: 0.9051\n",
            "Epoch 176/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 3.1696e-04 - accuracy: 1.0000 - val_loss: 0.7981 - val_accuracy: 0.9062\n",
            "Epoch 177/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 2.0173e-04 - accuracy: 1.0000 - val_loss: 0.7983 - val_accuracy: 0.9086\n",
            "Epoch 178/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0152 - accuracy: 0.9971 - val_loss: 0.9519 - val_accuracy: 0.8900\n",
            "Epoch 179/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0415 - accuracy: 0.9861 - val_loss: 0.8579 - val_accuracy: 0.8843\n",
            "Epoch 180/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.0218 - accuracy: 0.9931 - val_loss: 0.8586 - val_accuracy: 0.8762\n",
            "Epoch 181/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0504 - accuracy: 0.9847 - val_loss: 0.9246 - val_accuracy: 0.8692\n",
            "Epoch 182/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0720 - accuracy: 0.9800 - val_loss: 0.7694 - val_accuracy: 0.8877\n",
            "Epoch 183/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.8430 - val_accuracy: 0.9005\n",
            "Epoch 184/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0275 - accuracy: 0.9910 - val_loss: 0.8549 - val_accuracy: 0.8796\n",
            "Epoch 185/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 0.0129 - accuracy: 0.9951 - val_loss: 0.8434 - val_accuracy: 0.8889\n",
            "Epoch 186/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0055 - accuracy: 0.9986 - val_loss: 0.7675 - val_accuracy: 0.9051\n",
            "Epoch 187/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.7958 - val_accuracy: 0.8877\n",
            "Epoch 188/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.8338 - val_accuracy: 0.9120\n",
            "Epoch 189/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.7755 - val_accuracy: 0.9028\n",
            "Epoch 190/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.7557 - val_accuracy: 0.9062\n",
            "Epoch 191/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 7.3446e-04 - accuracy: 1.0000 - val_loss: 0.8364 - val_accuracy: 0.9074\n",
            "Epoch 192/500\n",
            "27/27 [==============================] - 4s 133ms/step - loss: 3.0568e-04 - accuracy: 1.0000 - val_loss: 0.8454 - val_accuracy: 0.9062\n",
            "Epoch 193/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 2.6767e-04 - accuracy: 1.0000 - val_loss: 0.8514 - val_accuracy: 0.9074\n",
            "Epoch 194/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.8630 - val_accuracy: 0.9062\n",
            "Epoch 195/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 3.5733e-04 - accuracy: 1.0000 - val_loss: 0.8352 - val_accuracy: 0.9028\n",
            "Epoch 196/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 2.3241e-04 - accuracy: 1.0000 - val_loss: 0.8333 - val_accuracy: 0.9097\n",
            "Epoch 197/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 3.0497e-04 - accuracy: 1.0000 - val_loss: 0.8405 - val_accuracy: 0.9086\n",
            "Epoch 198/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 1.6538e-04 - accuracy: 1.0000 - val_loss: 0.8544 - val_accuracy: 0.9062\n",
            "Epoch 199/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 2.4620e-04 - accuracy: 1.0000 - val_loss: 0.8568 - val_accuracy: 0.9062\n",
            "Epoch 200/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 1.8266e-04 - accuracy: 1.0000 - val_loss: 0.8780 - val_accuracy: 0.9062\n",
            "Epoch 201/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 1.3574e-04 - accuracy: 1.0000 - val_loss: 0.8800 - val_accuracy: 0.9051\n",
            "Epoch 202/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 1.5234e-04 - accuracy: 1.0000 - val_loss: 0.8550 - val_accuracy: 0.9074\n",
            "Epoch 203/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 1.5151e-04 - accuracy: 1.0000 - val_loss: 0.8547 - val_accuracy: 0.9074\n",
            "Epoch 204/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 1.1214e-04 - accuracy: 1.0000 - val_loss: 0.8695 - val_accuracy: 0.9074\n",
            "Epoch 205/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 1.5131e-04 - accuracy: 1.0000 - val_loss: 0.8720 - val_accuracy: 0.9062\n",
            "Epoch 206/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 1.4994e-04 - accuracy: 1.0000 - val_loss: 0.8913 - val_accuracy: 0.9039\n",
            "Epoch 207/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 1.0142e-04 - accuracy: 1.0000 - val_loss: 0.9181 - val_accuracy: 0.9062\n",
            "Epoch 208/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 1.0214 - val_accuracy: 0.8935\n",
            "Epoch 209/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0356 - accuracy: 0.9922 - val_loss: 1.1404 - val_accuracy: 0.8750\n",
            "Epoch 210/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.1677 - accuracy: 0.9604 - val_loss: 0.7346 - val_accuracy: 0.8692\n",
            "Epoch 211/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0547 - accuracy: 0.9800 - val_loss: 0.6874 - val_accuracy: 0.8947\n",
            "Epoch 212/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0145 - accuracy: 0.9962 - val_loss: 0.7363 - val_accuracy: 0.8877\n",
            "Epoch 213/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.7736 - val_accuracy: 0.8819\n",
            "Epoch 214/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0096 - accuracy: 0.9977 - val_loss: 0.7550 - val_accuracy: 0.8924\n",
            "Epoch 215/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.9155 - val_accuracy: 0.8924\n",
            "Epoch 216/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 1.0316 - val_accuracy: 0.8889\n",
            "Epoch 217/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0048 - accuracy: 0.9983 - val_loss: 0.9429 - val_accuracy: 0.8808\n",
            "Epoch 218/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.8856 - val_accuracy: 0.8993\n",
            "Epoch 219/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 0.9122 - val_accuracy: 0.8993\n",
            "Epoch 220/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.8844 - val_accuracy: 0.8947\n",
            "Epoch 221/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 0.9020 - val_accuracy: 0.9005\n",
            "Epoch 222/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.9405 - val_accuracy: 0.8958\n",
            "Epoch 223/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 0.0241 - accuracy: 0.9957 - val_loss: 1.0057 - val_accuracy: 0.8773\n",
            "Epoch 224/500\n",
            "27/27 [==============================] - 5s 195ms/step - loss: 0.0843 - accuracy: 0.9806 - val_loss: 0.8795 - val_accuracy: 0.8657\n",
            "Epoch 225/500\n",
            "27/27 [==============================] - 7s 244ms/step - loss: 0.0302 - accuracy: 0.9910 - val_loss: 0.6981 - val_accuracy: 0.8924\n",
            "Epoch 226/500\n",
            "27/27 [==============================] - 6s 237ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 0.7660 - val_accuracy: 0.9062\n",
            "Epoch 227/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0100 - accuracy: 0.9980 - val_loss: 0.7331 - val_accuracy: 0.8889\n",
            "Epoch 228/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 0.0204 - accuracy: 0.9957 - val_loss: 0.9068 - val_accuracy: 0.8935\n",
            "Epoch 229/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0202 - accuracy: 0.9954 - val_loss: 0.7716 - val_accuracy: 0.8970\n",
            "Epoch 230/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.8718 - val_accuracy: 0.8889\n",
            "Epoch 231/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.9122 - val_accuracy: 0.8889\n",
            "Epoch 232/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.8293 - val_accuracy: 0.8947\n",
            "Epoch 233/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.8145 - val_accuracy: 0.9016\n",
            "Epoch 234/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.8368 - val_accuracy: 0.8935\n",
            "Epoch 235/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 8.2995e-04 - accuracy: 1.0000 - val_loss: 0.8482 - val_accuracy: 0.8912\n",
            "Epoch 236/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.8641 - val_accuracy: 0.8970\n",
            "Epoch 237/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 8.9195e-04 - accuracy: 0.9997 - val_loss: 0.8567 - val_accuracy: 0.8958\n",
            "Epoch 238/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 5.6222e-04 - accuracy: 1.0000 - val_loss: 0.8426 - val_accuracy: 0.8981\n",
            "Epoch 239/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 3.5686e-04 - accuracy: 1.0000 - val_loss: 0.8451 - val_accuracy: 0.8993\n",
            "Epoch 240/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 2.0755e-04 - accuracy: 1.0000 - val_loss: 0.8694 - val_accuracy: 0.9005\n",
            "Epoch 241/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 2.9777e-04 - accuracy: 1.0000 - val_loss: 0.8748 - val_accuracy: 0.8970\n",
            "Epoch 242/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 2.8225e-04 - accuracy: 1.0000 - val_loss: 0.8761 - val_accuracy: 0.8958\n",
            "Epoch 243/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 3.3737e-04 - accuracy: 1.0000 - val_loss: 0.8875 - val_accuracy: 0.8981\n",
            "Epoch 244/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 2.1150e-04 - accuracy: 1.0000 - val_loss: 0.8984 - val_accuracy: 0.8958\n",
            "Epoch 245/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 3.8519e-04 - accuracy: 1.0000 - val_loss: 0.9159 - val_accuracy: 0.9005\n",
            "Epoch 246/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 6.7396e-04 - accuracy: 0.9997 - val_loss: 0.9320 - val_accuracy: 0.8970\n",
            "Epoch 247/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 3.3286e-04 - accuracy: 1.0000 - val_loss: 0.9471 - val_accuracy: 0.8970\n",
            "Epoch 248/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 2.1086e-04 - accuracy: 1.0000 - val_loss: 0.9708 - val_accuracy: 0.8935\n",
            "Epoch 249/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 2.8670e-04 - accuracy: 1.0000 - val_loss: 0.9591 - val_accuracy: 0.8947\n",
            "Epoch 250/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 1.4991e-04 - accuracy: 1.0000 - val_loss: 0.9517 - val_accuracy: 0.8970\n",
            "Epoch 251/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 1.4985e-04 - accuracy: 1.0000 - val_loss: 0.9562 - val_accuracy: 0.8958\n",
            "Epoch 252/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 9.3335e-04 - accuracy: 0.9997 - val_loss: 0.9296 - val_accuracy: 0.8958\n",
            "Epoch 253/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 1.0439 - val_accuracy: 0.8993\n",
            "Epoch 254/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 0.0435 - accuracy: 0.9887 - val_loss: 0.9313 - val_accuracy: 0.8692\n",
            "Epoch 255/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0346 - accuracy: 0.9905 - val_loss: 0.9377 - val_accuracy: 0.8889\n",
            "Epoch 256/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0285 - accuracy: 0.9910 - val_loss: 0.9424 - val_accuracy: 0.8854\n",
            "Epoch 257/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0109 - accuracy: 0.9962 - val_loss: 0.7932 - val_accuracy: 0.9028\n",
            "Epoch 258/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.9526 - val_accuracy: 0.8993\n",
            "Epoch 259/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.9150 - val_accuracy: 0.8935\n",
            "Epoch 260/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.9832 - val_accuracy: 0.8958\n",
            "Epoch 261/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 8.8548e-04 - accuracy: 1.0000 - val_loss: 1.0148 - val_accuracy: 0.8958\n",
            "Epoch 262/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 8.5645e-04 - accuracy: 0.9997 - val_loss: 1.0158 - val_accuracy: 0.8935\n",
            "Epoch 263/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 3.0211e-04 - accuracy: 1.0000 - val_loss: 0.9985 - val_accuracy: 0.8924\n",
            "Epoch 264/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 4.0537e-04 - accuracy: 1.0000 - val_loss: 0.9871 - val_accuracy: 0.8993\n",
            "Epoch 265/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 5.7999e-04 - accuracy: 1.0000 - val_loss: 1.0067 - val_accuracy: 0.9039\n",
            "Epoch 266/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 2.6462e-04 - accuracy: 1.0000 - val_loss: 1.0215 - val_accuracy: 0.8958\n",
            "Epoch 267/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 3.8517e-04 - accuracy: 1.0000 - val_loss: 1.0185 - val_accuracy: 0.9028\n",
            "Epoch 268/500\n",
            "27/27 [==============================] - 4s 134ms/step - loss: 2.4649e-04 - accuracy: 1.0000 - val_loss: 1.0305 - val_accuracy: 0.9028\n",
            "Epoch 269/500\n",
            "27/27 [==============================] - 4s 135ms/step - loss: 2.2367e-04 - accuracy: 1.0000 - val_loss: 1.0332 - val_accuracy: 0.9005\n",
            "Epoch 270/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 2.2070e-04 - accuracy: 1.0000 - val_loss: 1.0148 - val_accuracy: 0.8958\n",
            "Epoch 271/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 2.4835e-04 - accuracy: 1.0000 - val_loss: 1.0166 - val_accuracy: 0.8970\n",
            "Epoch 272/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 4.9953e-04 - accuracy: 0.9997 - val_loss: 1.0849 - val_accuracy: 0.8981\n",
            "Epoch 273/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 2.7231e-04 - accuracy: 1.0000 - val_loss: 1.0640 - val_accuracy: 0.8981\n",
            "Epoch 274/500\n",
            "27/27 [==============================] - 4s 144ms/step - loss: 9.7583e-05 - accuracy: 1.0000 - val_loss: 1.0230 - val_accuracy: 0.8970\n",
            "Epoch 275/500\n",
            "27/27 [==============================] - 4s 144ms/step - loss: 1.5574e-04 - accuracy: 1.0000 - val_loss: 1.0499 - val_accuracy: 0.8970\n",
            "Epoch 276/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 1.1471e-04 - accuracy: 1.0000 - val_loss: 1.0606 - val_accuracy: 0.8970\n",
            "Epoch 277/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 1.3216e-04 - accuracy: 1.0000 - val_loss: 1.0686 - val_accuracy: 0.8981\n",
            "Epoch 278/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 1.6489e-04 - accuracy: 1.0000 - val_loss: 1.0555 - val_accuracy: 0.8958\n",
            "Epoch 279/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 1.6866e-04 - accuracy: 1.0000 - val_loss: 1.0582 - val_accuracy: 0.8958\n",
            "Epoch 280/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 9.7535e-05 - accuracy: 1.0000 - val_loss: 1.0653 - val_accuracy: 0.8947\n",
            "Epoch 281/500\n",
            "27/27 [==============================] - 4s 145ms/step - loss: 6.8847e-05 - accuracy: 1.0000 - val_loss: 1.0701 - val_accuracy: 0.8958\n",
            "Epoch 282/500\n",
            "27/27 [==============================] - 4s 145ms/step - loss: 1.1872e-04 - accuracy: 1.0000 - val_loss: 1.0810 - val_accuracy: 0.8981\n",
            "Epoch 283/500\n",
            "27/27 [==============================] - 4s 144ms/step - loss: 6.2593e-05 - accuracy: 1.0000 - val_loss: 1.0822 - val_accuracy: 0.8970\n",
            "Epoch 284/500\n",
            "27/27 [==============================] - 4s 144ms/step - loss: 1.3751e-04 - accuracy: 1.0000 - val_loss: 1.0965 - val_accuracy: 0.8970\n",
            "Epoch 285/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 2.1998e-04 - accuracy: 1.0000 - val_loss: 1.1153 - val_accuracy: 0.9005\n",
            "Epoch 286/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 7.5617e-05 - accuracy: 1.0000 - val_loss: 1.1125 - val_accuracy: 0.9016\n",
            "Epoch 287/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 1.7881e-04 - accuracy: 1.0000 - val_loss: 1.1102 - val_accuracy: 0.9016\n",
            "Epoch 288/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 8.5891e-05 - accuracy: 1.0000 - val_loss: 1.1092 - val_accuracy: 0.9016\n",
            "Epoch 289/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 5.6614e-05 - accuracy: 1.0000 - val_loss: 1.1088 - val_accuracy: 0.8993\n",
            "Epoch 290/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 7.6140e-05 - accuracy: 1.0000 - val_loss: 1.1097 - val_accuracy: 0.8993\n",
            "Epoch 291/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 8.1278e-05 - accuracy: 1.0000 - val_loss: 1.1254 - val_accuracy: 0.8981\n",
            "Epoch 292/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 3.9564e-05 - accuracy: 1.0000 - val_loss: 1.1340 - val_accuracy: 0.8981\n",
            "Epoch 293/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 4.8632e-05 - accuracy: 1.0000 - val_loss: 1.1285 - val_accuracy: 0.8970\n",
            "Epoch 294/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 5.6478e-05 - accuracy: 1.0000 - val_loss: 1.1092 - val_accuracy: 0.9005\n",
            "Epoch 295/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 8.0332e-05 - accuracy: 1.0000 - val_loss: 1.0969 - val_accuracy: 0.8981\n",
            "Epoch 296/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 5.5264e-05 - accuracy: 1.0000 - val_loss: 1.1070 - val_accuracy: 0.8993\n",
            "Epoch 297/500\n",
            "27/27 [==============================] - 4s 164ms/step - loss: 2.9272e-05 - accuracy: 1.0000 - val_loss: 1.1169 - val_accuracy: 0.8981\n",
            "Epoch 298/500\n",
            "27/27 [==============================] - 4s 154ms/step - loss: 3.6330e-05 - accuracy: 1.0000 - val_loss: 1.1275 - val_accuracy: 0.8981\n",
            "Epoch 299/500\n",
            "27/27 [==============================] - 4s 149ms/step - loss: 3.0553e-04 - accuracy: 0.9997 - val_loss: 1.1153 - val_accuracy: 0.8993\n",
            "Epoch 300/500\n",
            "27/27 [==============================] - 4s 146ms/step - loss: 1.6801e-04 - accuracy: 1.0000 - val_loss: 1.1636 - val_accuracy: 0.9039\n",
            "Epoch 301/500\n",
            "27/27 [==============================] - 4s 143ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 1.2030 - val_accuracy: 0.8900\n",
            "Epoch 302/500\n",
            "27/27 [==============================] - 4s 143ms/step - loss: 0.1123 - accuracy: 0.9789 - val_loss: 1.2108 - val_accuracy: 0.8669\n",
            "Epoch 303/500\n",
            "27/27 [==============================] - 4s 146ms/step - loss: 0.1410 - accuracy: 0.9589 - val_loss: 0.6452 - val_accuracy: 0.8669\n",
            "Epoch 304/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0538 - accuracy: 0.9829 - val_loss: 0.6960 - val_accuracy: 0.8993\n",
            "Epoch 305/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 0.0225 - accuracy: 0.9922 - val_loss: 0.6638 - val_accuracy: 0.8912\n",
            "Epoch 306/500\n",
            "27/27 [==============================] - 4s 144ms/step - loss: 0.0089 - accuracy: 0.9971 - val_loss: 0.7596 - val_accuracy: 0.8958\n",
            "Epoch 307/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.7779 - val_accuracy: 0.8831\n",
            "Epoch 308/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.7646 - val_accuracy: 0.8993\n",
            "Epoch 309/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.7985 - val_accuracy: 0.8935\n",
            "Epoch 310/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.8066 - val_accuracy: 0.8993\n",
            "Epoch 311/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.8937 - val_accuracy: 0.9062\n",
            "Epoch 312/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.8591 - val_accuracy: 0.9051\n",
            "Epoch 313/500\n",
            "27/27 [==============================] - 4s 145ms/step - loss: 4.3406e-04 - accuracy: 1.0000 - val_loss: 0.8613 - val_accuracy: 0.9039\n",
            "Epoch 314/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 3.3639e-04 - accuracy: 1.0000 - val_loss: 0.8668 - val_accuracy: 0.9062\n",
            "Epoch 315/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 6.3714e-04 - accuracy: 0.9997 - val_loss: 0.8469 - val_accuracy: 0.9039\n",
            "Epoch 316/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.8677 - val_accuracy: 0.9016\n",
            "Epoch 317/500\n",
            "27/27 [==============================] - 4s 143ms/step - loss: 4.9537e-04 - accuracy: 1.0000 - val_loss: 0.8770 - val_accuracy: 0.9016\n",
            "Epoch 318/500\n",
            "27/27 [==============================] - 4s 151ms/step - loss: 2.0964e-04 - accuracy: 1.0000 - val_loss: 0.8730 - val_accuracy: 0.9005\n",
            "Epoch 319/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 1.6475e-04 - accuracy: 1.0000 - val_loss: 0.8771 - val_accuracy: 0.9005\n",
            "Epoch 320/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 2.1195e-04 - accuracy: 1.0000 - val_loss: 0.8861 - val_accuracy: 0.9016\n",
            "Epoch 321/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 2.0192e-04 - accuracy: 1.0000 - val_loss: 0.8977 - val_accuracy: 0.9028\n",
            "Epoch 322/500\n",
            "27/27 [==============================] - 4s 149ms/step - loss: 4.5620e-04 - accuracy: 1.0000 - val_loss: 0.8793 - val_accuracy: 0.9016\n",
            "Epoch 323/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 1.3053e-04 - accuracy: 1.0000 - val_loss: 0.8776 - val_accuracy: 0.9005\n",
            "Epoch 324/500\n",
            "27/27 [==============================] - 4s 144ms/step - loss: 3.2736e-04 - accuracy: 1.0000 - val_loss: 0.8933 - val_accuracy: 0.8981\n",
            "Epoch 325/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 1.1559e-04 - accuracy: 1.0000 - val_loss: 0.9014 - val_accuracy: 0.9051\n",
            "Epoch 326/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.9691 - val_accuracy: 0.8889\n",
            "Epoch 327/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.9849 - val_accuracy: 0.9051\n",
            "Epoch 328/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 0.0039 - accuracy: 0.9980 - val_loss: 1.0758 - val_accuracy: 0.8981\n",
            "Epoch 329/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 1.0134 - val_accuracy: 0.8993\n",
            "Epoch 330/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 1.0204 - val_accuracy: 0.9039\n",
            "Epoch 331/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 1.2105 - val_accuracy: 0.8738\n",
            "Epoch 332/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0655 - accuracy: 0.9832 - val_loss: 1.0397 - val_accuracy: 0.8657\n",
            "Epoch 333/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0459 - accuracy: 0.9861 - val_loss: 0.8594 - val_accuracy: 0.8762\n",
            "Epoch 334/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0516 - accuracy: 0.9850 - val_loss: 0.7284 - val_accuracy: 0.8912\n",
            "Epoch 335/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0270 - accuracy: 0.9925 - val_loss: 0.7705 - val_accuracy: 0.8762\n",
            "Epoch 336/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 0.6866 - val_accuracy: 0.8912\n",
            "Epoch 337/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 0.7033 - val_accuracy: 0.8993\n",
            "Epoch 338/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.7787 - val_accuracy: 0.8924\n",
            "Epoch 339/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 0.0186 - accuracy: 0.9962 - val_loss: 0.9024 - val_accuracy: 0.8958\n",
            "Epoch 340/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0252 - accuracy: 0.9931 - val_loss: 0.8673 - val_accuracy: 0.8935\n",
            "Epoch 341/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.7483 - val_accuracy: 0.8970\n",
            "Epoch 342/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.7718 - val_accuracy: 0.9051\n",
            "Epoch 343/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.7578 - val_accuracy: 0.9028\n",
            "Epoch 344/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 9.7929e-04 - accuracy: 0.9997 - val_loss: 0.7856 - val_accuracy: 0.9086\n",
            "Epoch 345/500\n",
            "27/27 [==============================] - 4s 143ms/step - loss: 5.0588e-04 - accuracy: 1.0000 - val_loss: 0.8209 - val_accuracy: 0.9051\n",
            "Epoch 346/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 4.1929e-04 - accuracy: 1.0000 - val_loss: 0.8302 - val_accuracy: 0.9062\n",
            "Epoch 347/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 2.9313e-04 - accuracy: 1.0000 - val_loss: 0.8374 - val_accuracy: 0.9062\n",
            "Epoch 348/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 1.8353e-04 - accuracy: 1.0000 - val_loss: 0.8463 - val_accuracy: 0.9074\n",
            "Epoch 349/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 1.8923e-04 - accuracy: 1.0000 - val_loss: 0.8469 - val_accuracy: 0.9074\n",
            "Epoch 350/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 4.1059e-04 - accuracy: 1.0000 - val_loss: 0.8577 - val_accuracy: 0.9144\n",
            "Epoch 351/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 3.7141e-04 - accuracy: 1.0000 - val_loss: 0.8530 - val_accuracy: 0.9062\n",
            "Epoch 352/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 1.5629e-04 - accuracy: 1.0000 - val_loss: 0.8613 - val_accuracy: 0.9074\n",
            "Epoch 353/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 1.9360e-04 - accuracy: 1.0000 - val_loss: 0.8671 - val_accuracy: 0.9086\n",
            "Epoch 354/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 2.0537e-04 - accuracy: 1.0000 - val_loss: 0.8887 - val_accuracy: 0.9074\n",
            "Epoch 355/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 1.0467e-04 - accuracy: 1.0000 - val_loss: 0.9030 - val_accuracy: 0.9074\n",
            "Epoch 356/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 1.1967e-04 - accuracy: 1.0000 - val_loss: 0.9089 - val_accuracy: 0.9062\n",
            "Epoch 357/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 8.1453e-05 - accuracy: 1.0000 - val_loss: 0.9151 - val_accuracy: 0.9051\n",
            "Epoch 358/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 4.3049e-04 - accuracy: 0.9997 - val_loss: 0.8556 - val_accuracy: 0.9097\n",
            "Epoch 359/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 1.9628e-04 - accuracy: 1.0000 - val_loss: 0.8815 - val_accuracy: 0.9062\n",
            "Epoch 360/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 1.0153e-04 - accuracy: 1.0000 - val_loss: 0.8916 - val_accuracy: 0.9074\n",
            "Epoch 361/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 1.2522e-04 - accuracy: 1.0000 - val_loss: 0.8978 - val_accuracy: 0.9086\n",
            "Epoch 362/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 7.3640e-05 - accuracy: 1.0000 - val_loss: 0.8998 - val_accuracy: 0.9109\n",
            "Epoch 363/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 2.4464e-04 - accuracy: 1.0000 - val_loss: 0.9326 - val_accuracy: 0.9074\n",
            "Epoch 364/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.9473 - val_accuracy: 0.8935\n",
            "Epoch 365/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0137 - accuracy: 0.9962 - val_loss: 0.9035 - val_accuracy: 0.8889\n",
            "Epoch 366/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0135 - accuracy: 0.9951 - val_loss: 0.8270 - val_accuracy: 0.9005\n",
            "Epoch 367/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 0.0259 - accuracy: 0.9925 - val_loss: 1.0406 - val_accuracy: 0.8796\n",
            "Epoch 368/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0361 - accuracy: 0.9907 - val_loss: 0.9760 - val_accuracy: 0.8866\n",
            "Epoch 369/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 0.0419 - accuracy: 0.9905 - val_loss: 1.3661 - val_accuracy: 0.8611\n",
            "Epoch 370/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0374 - accuracy: 0.9884 - val_loss: 0.7129 - val_accuracy: 0.8935\n",
            "Epoch 371/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.7622 - val_accuracy: 0.9005\n",
            "Epoch 372/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.7195 - val_accuracy: 0.8981\n",
            "Epoch 373/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.7522 - val_accuracy: 0.9086\n",
            "Epoch 374/500\n",
            "27/27 [==============================] - 4s 143ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.7406 - val_accuracy: 0.9062\n",
            "Epoch 375/500\n",
            "27/27 [==============================] - 4s 146ms/step - loss: 5.2763e-04 - accuracy: 1.0000 - val_loss: 0.7296 - val_accuracy: 0.9051\n",
            "Epoch 376/500\n",
            "27/27 [==============================] - 4s 146ms/step - loss: 4.5678e-04 - accuracy: 1.0000 - val_loss: 0.7534 - val_accuracy: 0.9074\n",
            "Epoch 377/500\n",
            "27/27 [==============================] - 4s 146ms/step - loss: 2.7464e-04 - accuracy: 1.0000 - val_loss: 0.7695 - val_accuracy: 0.9051\n",
            "Epoch 378/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 1.8991e-04 - accuracy: 1.0000 - val_loss: 0.7839 - val_accuracy: 0.9062\n",
            "Epoch 379/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 2.0672e-04 - accuracy: 1.0000 - val_loss: 0.7875 - val_accuracy: 0.9074\n",
            "Epoch 380/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 1.7146e-04 - accuracy: 1.0000 - val_loss: 0.7951 - val_accuracy: 0.9086\n",
            "Epoch 381/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 6.8549e-04 - accuracy: 0.9997 - val_loss: 0.7712 - val_accuracy: 0.9074\n",
            "Epoch 382/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 6.2814e-04 - accuracy: 0.9997 - val_loss: 0.8594 - val_accuracy: 0.9097\n",
            "Epoch 383/500\n",
            "27/27 [==============================] - 4s 136ms/step - loss: 6.8233e-04 - accuracy: 0.9997 - val_loss: 0.8226 - val_accuracy: 0.9074\n",
            "Epoch 384/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 1.3773e-04 - accuracy: 1.0000 - val_loss: 0.8362 - val_accuracy: 0.9051\n",
            "Epoch 385/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 1.4852e-04 - accuracy: 1.0000 - val_loss: 0.8470 - val_accuracy: 0.9062\n",
            "Epoch 386/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 3.5889e-04 - accuracy: 1.0000 - val_loss: 0.8387 - val_accuracy: 0.9062\n",
            "Epoch 387/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 1.4107e-04 - accuracy: 1.0000 - val_loss: 0.8528 - val_accuracy: 0.9062\n",
            "Epoch 388/500\n",
            "27/27 [==============================] - 4s 143ms/step - loss: 1.2763e-04 - accuracy: 1.0000 - val_loss: 0.8702 - val_accuracy: 0.9062\n",
            "Epoch 389/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 2.1534e-04 - accuracy: 1.0000 - val_loss: 0.8899 - val_accuracy: 0.9074\n",
            "Epoch 390/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 1.5035e-04 - accuracy: 1.0000 - val_loss: 0.9011 - val_accuracy: 0.9086\n",
            "Epoch 391/500\n",
            "27/27 [==============================] - 4s 144ms/step - loss: 8.1220e-05 - accuracy: 1.0000 - val_loss: 0.8987 - val_accuracy: 0.9097\n",
            "Epoch 392/500\n",
            "27/27 [==============================] - 4s 144ms/step - loss: 1.4390e-04 - accuracy: 1.0000 - val_loss: 0.9094 - val_accuracy: 0.9074\n",
            "Epoch 393/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 5.5707e-05 - accuracy: 1.0000 - val_loss: 0.9188 - val_accuracy: 0.9062\n",
            "Epoch 394/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 3.0463e-04 - accuracy: 0.9997 - val_loss: 0.9091 - val_accuracy: 0.9086\n",
            "Epoch 395/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 5.8911e-05 - accuracy: 1.0000 - val_loss: 0.9112 - val_accuracy: 0.9074\n",
            "Epoch 396/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 1.1285e-04 - accuracy: 1.0000 - val_loss: 0.9220 - val_accuracy: 0.9097\n",
            "Epoch 397/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 3.3618e-05 - accuracy: 1.0000 - val_loss: 0.9290 - val_accuracy: 0.9097\n",
            "Epoch 398/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 3.6714e-05 - accuracy: 1.0000 - val_loss: 0.9367 - val_accuracy: 0.9097\n",
            "Epoch 399/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 3.8725e-05 - accuracy: 1.0000 - val_loss: 0.9462 - val_accuracy: 0.9097\n",
            "Epoch 400/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 1.7263e-05 - accuracy: 1.0000 - val_loss: 0.9512 - val_accuracy: 0.9086\n",
            "Epoch 401/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 3.9502e-05 - accuracy: 1.0000 - val_loss: 0.9559 - val_accuracy: 0.9086\n",
            "Epoch 402/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 3.0721e-05 - accuracy: 1.0000 - val_loss: 0.9611 - val_accuracy: 0.9097\n",
            "Epoch 403/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 2.9440e-05 - accuracy: 1.0000 - val_loss: 0.9664 - val_accuracy: 0.9086\n",
            "Epoch 404/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 5.4433e-05 - accuracy: 1.0000 - val_loss: 0.9814 - val_accuracy: 0.9086\n",
            "Epoch 405/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 4.0548e-05 - accuracy: 1.0000 - val_loss: 0.9843 - val_accuracy: 0.9086\n",
            "Epoch 406/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 5.0232e-05 - accuracy: 1.0000 - val_loss: 0.9846 - val_accuracy: 0.9074\n",
            "Epoch 407/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 1.0871e-04 - accuracy: 1.0000 - val_loss: 0.9860 - val_accuracy: 0.9097\n",
            "Epoch 408/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 4.4708e-05 - accuracy: 1.0000 - val_loss: 0.9968 - val_accuracy: 0.9086\n",
            "Epoch 409/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 6.6046e-05 - accuracy: 1.0000 - val_loss: 1.0154 - val_accuracy: 0.9086\n",
            "Epoch 410/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 1.8545e-05 - accuracy: 1.0000 - val_loss: 1.0176 - val_accuracy: 0.9086\n",
            "Epoch 411/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 1.9782e-05 - accuracy: 1.0000 - val_loss: 1.0241 - val_accuracy: 0.9086\n",
            "Epoch 412/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 4.7070e-05 - accuracy: 1.0000 - val_loss: 1.0310 - val_accuracy: 0.9086\n",
            "Epoch 413/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 1.5480e-05 - accuracy: 1.0000 - val_loss: 1.0339 - val_accuracy: 0.9086\n",
            "Epoch 414/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 2.5641e-05 - accuracy: 1.0000 - val_loss: 1.0404 - val_accuracy: 0.9086\n",
            "Epoch 415/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 2.2468e-05 - accuracy: 1.0000 - val_loss: 1.0413 - val_accuracy: 0.9086\n",
            "Epoch 416/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 2.5441e-05 - accuracy: 1.0000 - val_loss: 1.0408 - val_accuracy: 0.9086\n",
            "Epoch 417/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 1.5839e-05 - accuracy: 1.0000 - val_loss: 1.0414 - val_accuracy: 0.9086\n",
            "Epoch 418/500\n",
            "27/27 [==============================] - 4s 150ms/step - loss: 2.4295e-05 - accuracy: 1.0000 - val_loss: 1.0498 - val_accuracy: 0.9097\n",
            "Epoch 419/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 9.4123e-05 - accuracy: 1.0000 - val_loss: 1.0327 - val_accuracy: 0.9074\n",
            "Epoch 420/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 7.0982e-05 - accuracy: 1.0000 - val_loss: 1.0287 - val_accuracy: 0.9086\n",
            "Epoch 421/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 5.2445e-05 - accuracy: 1.0000 - val_loss: 1.0837 - val_accuracy: 0.9005\n",
            "Epoch 422/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 4.0077e-05 - accuracy: 1.0000 - val_loss: 1.1050 - val_accuracy: 0.9005\n",
            "Epoch 423/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 8.4112e-05 - accuracy: 1.0000 - val_loss: 1.0949 - val_accuracy: 0.9039\n",
            "Epoch 424/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 7.0956e-05 - accuracy: 1.0000 - val_loss: 1.0866 - val_accuracy: 0.9039\n",
            "Epoch 425/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 4.4517e-05 - accuracy: 1.0000 - val_loss: 1.1125 - val_accuracy: 0.9005\n",
            "Epoch 426/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 1.6251e-05 - accuracy: 1.0000 - val_loss: 1.1271 - val_accuracy: 0.9005\n",
            "Epoch 427/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 2.6962e-05 - accuracy: 1.0000 - val_loss: 1.1371 - val_accuracy: 0.9005\n",
            "Epoch 428/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 3.9540e-04 - accuracy: 1.0000 - val_loss: 1.1700 - val_accuracy: 0.8981\n",
            "Epoch 429/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 4.6490e-04 - accuracy: 0.9997 - val_loss: 1.1364 - val_accuracy: 0.9074\n",
            "Epoch 430/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0115 - accuracy: 0.9962 - val_loss: 1.0796 - val_accuracy: 0.8947\n",
            "Epoch 431/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.1656 - accuracy: 0.9627 - val_loss: 0.8615 - val_accuracy: 0.8773\n",
            "Epoch 432/500\n",
            "27/27 [==============================] - 4s 143ms/step - loss: 0.0570 - accuracy: 0.9823 - val_loss: 0.7710 - val_accuracy: 0.8993\n",
            "Epoch 433/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 0.7622 - val_accuracy: 0.8993\n",
            "Epoch 434/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0230 - accuracy: 0.9919 - val_loss: 0.7620 - val_accuracy: 0.8947\n",
            "Epoch 435/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 0.0165 - accuracy: 0.9957 - val_loss: 0.8463 - val_accuracy: 0.8970\n",
            "Epoch 436/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 0.0330 - accuracy: 0.9907 - val_loss: 0.8325 - val_accuracy: 0.8843\n",
            "Epoch 437/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0199 - accuracy: 0.9945 - val_loss: 0.7121 - val_accuracy: 0.8993\n",
            "Epoch 438/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 0.0045 - accuracy: 0.9983 - val_loss: 0.8211 - val_accuracy: 0.9016\n",
            "Epoch 439/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.8173 - val_accuracy: 0.8970\n",
            "Epoch 440/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.8469 - val_accuracy: 0.8935\n",
            "Epoch 441/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 0.0021 - accuracy: 0.9991 - val_loss: 0.8571 - val_accuracy: 0.9039\n",
            "Epoch 442/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 4.8449e-04 - accuracy: 1.0000 - val_loss: 0.9039 - val_accuracy: 0.9097\n",
            "Epoch 443/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 5.3236e-04 - accuracy: 0.9997 - val_loss: 0.9138 - val_accuracy: 0.9062\n",
            "Epoch 444/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 5.2963e-04 - accuracy: 1.0000 - val_loss: 0.9224 - val_accuracy: 0.9051\n",
            "Epoch 445/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 3.2755e-04 - accuracy: 1.0000 - val_loss: 0.9919 - val_accuracy: 0.9097\n",
            "Epoch 446/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 1.0721 - val_accuracy: 0.9016\n",
            "Epoch 447/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0050 - accuracy: 0.9980 - val_loss: 0.9585 - val_accuracy: 0.9074\n",
            "Epoch 448/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0357 - accuracy: 0.9922 - val_loss: 0.9073 - val_accuracy: 0.8912\n",
            "Epoch 449/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0454 - accuracy: 0.9890 - val_loss: 0.8404 - val_accuracy: 0.8750\n",
            "Epoch 450/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0202 - accuracy: 0.9928 - val_loss: 0.8640 - val_accuracy: 0.8935\n",
            "Epoch 451/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0091 - accuracy: 0.9965 - val_loss: 0.7825 - val_accuracy: 0.8993\n",
            "Epoch 452/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.8379 - val_accuracy: 0.9005\n",
            "Epoch 453/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.8593 - val_accuracy: 0.8877\n",
            "Epoch 454/500\n",
            "27/27 [==============================] - 4s 137ms/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.8701 - val_accuracy: 0.9051\n",
            "Epoch 455/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.8887 - val_accuracy: 0.9062\n",
            "Epoch 456/500\n",
            "27/27 [==============================] - 4s 157ms/step - loss: 6.4620e-04 - accuracy: 1.0000 - val_loss: 0.8804 - val_accuracy: 0.9062\n",
            "Epoch 457/500\n",
            "27/27 [==============================] - 4s 145ms/step - loss: 4.0916e-04 - accuracy: 1.0000 - val_loss: 0.8716 - val_accuracy: 0.9039\n",
            "Epoch 458/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 1.7949e-04 - accuracy: 1.0000 - val_loss: 0.8807 - val_accuracy: 0.9039\n",
            "Epoch 459/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 1.7328e-04 - accuracy: 1.0000 - val_loss: 0.8882 - val_accuracy: 0.9051\n",
            "Epoch 460/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 4.6610e-04 - accuracy: 1.0000 - val_loss: 0.8756 - val_accuracy: 0.9016\n",
            "Epoch 461/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 2.7085e-04 - accuracy: 1.0000 - val_loss: 0.8817 - val_accuracy: 0.8981\n",
            "Epoch 462/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 2.1878e-04 - accuracy: 1.0000 - val_loss: 0.9062 - val_accuracy: 0.9028\n",
            "Epoch 463/500\n",
            "27/27 [==============================] - 4s 138ms/step - loss: 1.8525e-04 - accuracy: 1.0000 - val_loss: 0.9271 - val_accuracy: 0.9028\n",
            "Epoch 464/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 1.1774e-04 - accuracy: 1.0000 - val_loss: 0.9402 - val_accuracy: 0.9028\n",
            "Epoch 465/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 1.6600e-04 - accuracy: 1.0000 - val_loss: 0.9420 - val_accuracy: 0.9028\n",
            "Epoch 466/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 7.0105e-05 - accuracy: 1.0000 - val_loss: 0.9510 - val_accuracy: 0.9016\n",
            "Epoch 467/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 1.4559e-04 - accuracy: 1.0000 - val_loss: 0.9678 - val_accuracy: 0.9016\n",
            "Epoch 468/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 6.4825e-05 - accuracy: 1.0000 - val_loss: 0.9763 - val_accuracy: 0.9016\n",
            "Epoch 469/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 4.4678e-05 - accuracy: 1.0000 - val_loss: 0.9782 - val_accuracy: 0.9016\n",
            "Epoch 470/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 9.0703e-05 - accuracy: 1.0000 - val_loss: 0.9722 - val_accuracy: 0.9016\n",
            "Epoch 471/500\n",
            "27/27 [==============================] - 4s 143ms/step - loss: 9.5332e-05 - accuracy: 1.0000 - val_loss: 0.9472 - val_accuracy: 0.9051\n",
            "Epoch 472/500\n",
            "27/27 [==============================] - 4s 149ms/step - loss: 1.1976e-04 - accuracy: 1.0000 - val_loss: 0.9396 - val_accuracy: 0.9051\n",
            "Epoch 473/500\n",
            "27/27 [==============================] - 4s 143ms/step - loss: 1.6522e-04 - accuracy: 1.0000 - val_loss: 0.9663 - val_accuracy: 0.9074\n",
            "Epoch 474/500\n",
            "27/27 [==============================] - 4s 145ms/step - loss: 1.0032e-04 - accuracy: 1.0000 - val_loss: 0.9783 - val_accuracy: 0.9051\n",
            "Epoch 475/500\n",
            "27/27 [==============================] - 4s 143ms/step - loss: 5.2960e-05 - accuracy: 1.0000 - val_loss: 0.9642 - val_accuracy: 0.9039\n",
            "Epoch 476/500\n",
            "27/27 [==============================] - 4s 146ms/step - loss: 3.8902e-05 - accuracy: 1.0000 - val_loss: 0.9640 - val_accuracy: 0.9051\n",
            "Epoch 477/500\n",
            "27/27 [==============================] - 4s 144ms/step - loss: 5.4610e-05 - accuracy: 1.0000 - val_loss: 0.9688 - val_accuracy: 0.9039\n",
            "Epoch 478/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 3.4612e-04 - accuracy: 0.9997 - val_loss: 0.9736 - val_accuracy: 0.9062\n",
            "Epoch 479/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 1.0585e-04 - accuracy: 1.0000 - val_loss: 0.9868 - val_accuracy: 0.9005\n",
            "Epoch 480/500\n",
            "27/27 [==============================] - 4s 143ms/step - loss: 7.3527e-05 - accuracy: 1.0000 - val_loss: 0.9840 - val_accuracy: 0.9016\n",
            "Epoch 481/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 9.0753e-05 - accuracy: 1.0000 - val_loss: 0.9816 - val_accuracy: 0.9039\n",
            "Epoch 482/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 5.8582e-05 - accuracy: 1.0000 - val_loss: 0.9782 - val_accuracy: 0.9039\n",
            "Epoch 483/500\n",
            "27/27 [==============================] - 4s 143ms/step - loss: 5.0157e-05 - accuracy: 1.0000 - val_loss: 0.9817 - val_accuracy: 0.9062\n",
            "Epoch 484/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 1.3029e-04 - accuracy: 1.0000 - val_loss: 0.9667 - val_accuracy: 0.9051\n",
            "Epoch 485/500\n",
            "27/27 [==============================] - 4s 145ms/step - loss: 1.7005e-04 - accuracy: 1.0000 - val_loss: 0.9981 - val_accuracy: 0.9074\n",
            "Epoch 486/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 6.5448e-05 - accuracy: 1.0000 - val_loss: 0.9989 - val_accuracy: 0.9062\n",
            "Epoch 487/500\n",
            "27/27 [==============================] - 4s 143ms/step - loss: 5.6457e-05 - accuracy: 1.0000 - val_loss: 1.0047 - val_accuracy: 0.9062\n",
            "Epoch 488/500\n",
            "27/27 [==============================] - 4s 146ms/step - loss: 5.0244e-05 - accuracy: 1.0000 - val_loss: 1.0090 - val_accuracy: 0.9051\n",
            "Epoch 489/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 4.8086e-05 - accuracy: 1.0000 - val_loss: 1.0116 - val_accuracy: 0.9062\n",
            "Epoch 490/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 3.5357e-05 - accuracy: 1.0000 - val_loss: 1.0138 - val_accuracy: 0.9051\n",
            "Epoch 491/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 3.6015e-05 - accuracy: 1.0000 - val_loss: 1.0204 - val_accuracy: 0.9039\n",
            "Epoch 492/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 2.3462e-05 - accuracy: 1.0000 - val_loss: 1.0234 - val_accuracy: 0.9051\n",
            "Epoch 493/500\n",
            "27/27 [==============================] - 4s 145ms/step - loss: 3.8920e-05 - accuracy: 1.0000 - val_loss: 1.0274 - val_accuracy: 0.9062\n",
            "Epoch 494/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 4.8839e-05 - accuracy: 1.0000 - val_loss: 1.0262 - val_accuracy: 0.9062\n",
            "Epoch 495/500\n",
            "27/27 [==============================] - 4s 142ms/step - loss: 1.5627e-05 - accuracy: 1.0000 - val_loss: 1.0285 - val_accuracy: 0.9051\n",
            "Epoch 496/500\n",
            "27/27 [==============================] - 4s 145ms/step - loss: 8.1868e-05 - accuracy: 1.0000 - val_loss: 1.0404 - val_accuracy: 0.9062\n",
            "Epoch 497/500\n",
            "27/27 [==============================] - 4s 139ms/step - loss: 3.6280e-05 - accuracy: 1.0000 - val_loss: 1.0448 - val_accuracy: 0.9062\n",
            "Epoch 498/500\n",
            "27/27 [==============================] - 4s 140ms/step - loss: 2.3865e-05 - accuracy: 1.0000 - val_loss: 1.0468 - val_accuracy: 0.9074\n",
            "Epoch 499/500\n",
            "27/27 [==============================] - 4s 144ms/step - loss: 3.2996e-05 - accuracy: 1.0000 - val_loss: 1.0522 - val_accuracy: 0.9074\n",
            "Epoch 500/500\n",
            "27/27 [==============================] - 4s 141ms/step - loss: 6.1915e-05 - accuracy: 1.0000 - val_loss: 1.0643 - val_accuracy: 0.9086\n",
            "15/15 [==============================] - 0s 26ms/step - loss: 1.1615 - accuracy: 0.8917\n"
          ]
        }
      ],
      "source": [
        "network_1.fit(train_images, train_labels, epochs=500, batch_size=128, validation_data=(val_images, val_labels), verbose=1)\n",
        "\n",
        "test_loss, test_acc = network_1.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss8, test_acc8 = network_1.evaluate(test_images, test_labels)\n",
        "print('test_acc:', test_acc8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfYk8T2RwMEy",
        "outputId": "1ec839e6-8245-4a55-d4d1-b56783e53490"
      },
      "id": "mfYk8T2RwMEy",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15/15 [==============================] - 0s 23ms/step - loss: 1.1615 - accuracy: 0.8917\n",
            "test_acc: 0.8916666507720947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_class=[]\n",
        "for x in range(0,len(test_images)):\n",
        "  t_class.append(np.argmax(test_labels[x]))\n",
        "\n",
        "t_class=np.array(t_class)  \n",
        "t_class.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksTM4HwmwLZB",
        "outputId": "5e366e74-0ae2-4301-b62c-60dfc6e13f47"
      },
      "id": "ksTM4HwmwLZB",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(480,)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction=network_1.predict(test_images)\n",
        "p_class=[]      \n",
        "for x in range(0,len(test_images)):\n",
        "  p_class.append(np.argmax(prediction[x]))\n",
        "\n",
        "p_class=np.array(p_class)                           \n",
        "p_class.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO4A2xuLwQH1",
        "outputId": "87d2eeeb-3aa6-422e-987d-1b6b13edff50"
      },
      "id": "nO4A2xuLwQH1",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(480,)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm2=tf.math.confusion_matrix(a_class , p_class)\n",
        "cm2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8QbfqDtwTF0",
        "outputId": "d0f47623-3dfd-434c-e826-bcca90c1e244"
      },
      "id": "T8QbfqDtwTF0",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6, 6), dtype=int32, numpy=\n",
              "array([[69,  1,  0,  9,  4,  0],\n",
              "       [ 3, 73,  0,  0,  2,  0],\n",
              "       [ 0,  2, 77,  0,  0,  9],\n",
              "       [ 1,  0,  0, 69,  3,  0],\n",
              "       [ 7,  0,  0,  1, 73,  0],\n",
              "       [ 1,  1,  3,  0,  5, 67]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy for Lego block type brick 1x2')\n",
        "print(cm2[0,0]/sum(cm2[:,0]))\n",
        "print('Accuracy for Lego block type brick 2x2')\n",
        "print(cm2[1,1]/sum(cm2[:,1]))\n",
        "print('Accuracy for Lego block type brick 2x4')\n",
        "print(cm2[2,2]/sum(cm2[:,2]))\n",
        "print('Accuracy for Lego block type plate 1x2')\n",
        "print(cm2[3,3]/sum(cm2[:,3]))\n",
        "print('Accuracy for Lego block type plate 2x2')\n",
        "print(cm2[4,4]/sum(cm2[:,4]))\n",
        "print('Accuracy for Lego block type plate 2x4')\n",
        "print(cm2[5,5]/sum(cm2[:,5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOaX90e5wU5P",
        "outputId": "a9591fbe-8e3d-4390-ee8e-ffe254749582"
      },
      "id": "dOaX90e5wU5P",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for Lego block type brick 1x2\n",
            "tf.Tensor(0.8518518518518519, shape=(), dtype=float64)\n",
            "Accuracy for Lego block type brick 2x2\n",
            "tf.Tensor(0.948051948051948, shape=(), dtype=float64)\n",
            "Accuracy for Lego block type brick 2x4\n",
            "tf.Tensor(0.9625, shape=(), dtype=float64)\n",
            "Accuracy for Lego block type plate 1x2\n",
            "tf.Tensor(0.8734177215189873, shape=(), dtype=float64)\n",
            "Accuracy for Lego block type plate 2x2\n",
            "tf.Tensor(0.8390804597701149, shape=(), dtype=float64)\n",
            "Accuracy for Lego block type plate 2x4\n",
            "tf.Tensor(0.881578947368421, shape=(), dtype=float64)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Lab_2 - Copy.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}